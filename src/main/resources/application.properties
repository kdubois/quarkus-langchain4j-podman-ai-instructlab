quarkus.langchain4j.openai.base-url=http://localhost:35000/v1
#quarkus.langchain4j.openai.base-url=http://localhost:11434/v1
# Configure openai server to use a specific model
#quarkus.langchain4j.openai.chat-model.model-name=llama3.1
# Set timeout to 3 minutes
quarkus.langchain4j.openai.timeout=180s
# Enable logging of both requests and responses
quarkus.langchain4j.openai.log-requests=true
quarkus.langchain4j.openai.log-responses=true